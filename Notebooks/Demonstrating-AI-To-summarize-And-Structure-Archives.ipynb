{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we will build a very basic pipeline for converting scanned documents to an OCR format. The idea is to demonstrate how we can scalably use out of the box OCR services like AWS textract to quickly and accurately convert vast amounts of scanned PDFs to raw text. This converted text can then be programmatically fed to large language models for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Configurations\n",
    "Here, we create some preliminary configurations.\n",
    "1. First we set up a S3 bucket name where all the raw input books will be stored. The bucket that has been created for this purpose is `cps-scanned-archival-material`.\n",
    "2. We need textract to be able to access the files in this bucket and hence we will have to amend the default bucket policy to provide textract with read access. We use the following policy\n",
    "```\n",
    "                {\n",
    "                    \"Version\": \"2012-10-17\",\n",
    "                    \"Statement\": [\n",
    "                        {\n",
    "                            \"Effect\": \"Allow\",\n",
    "                            \"Principal\": {\n",
    "                                \"Service\": \"textract.amazonaws.com\"\n",
    "                            },\n",
    "                            \"Action\": [\n",
    "                                \"s3:GetObject\",\n",
    "                                \"s3:*\"\n",
    "                            ],\n",
    "                            \"Resource\": \"arn:aws:s3:::cps-scanned-archival-material/*\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "```\n",
    "3. We then set up the S3 client as needed.\n",
    "4. We will also set up a textract client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BasicConfigurations:\n",
    "    BucketName: str\n",
    "\n",
    "basic_configurations = BasicConfigurations(BucketName='cps-scanned-archival-material')\n",
    "# Set up the s3 client\n",
    "s3_client = boto3.client('s3')\n",
    "textract = boto3.client('textract', region_name='ap-south-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Input Preparation\n",
    "Prior to proceeding further we have to prepare some sample inputs. We will pick up 5 pdf documents from the CPS website and use them for our purposes of analysis. We have chosen the following 4 documents, each with differing characteristics:\n",
    "1. **BV07 - Indian Rulers and The British Government** - Type written pages, some of which are blurred. A total of 105 pages of text. 19.2 MB\n",
    "2. **BV12 - British Rule in South India** - Slightly better scan quality, but some interesting orientation of the scan (a slight clockwise tilt). 96 pages - 18.4 MB\n",
    "3. **CPM03 - Reports of the Agitation in Bihar** - Very Poor Original Document quality. Fading print, stains on the page. 50 Pages\n",
    "4. **TS05 - Manufacture of Iron and Steel** Poor quality typescripts with blurred type and annotations on the margins. 15 pages.\n",
    "\n",
    "The documents were chosen to be as contextually diverse as possible while being subjectively difficult to convert to a raw text form. They have various sources of error and confusion ranging from poor scan quality to hand annotations and corrections. These documents were loaded to the S3 buckets using the script below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = []\n",
    "folder_path = 'pdf_files'\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        pdf_files.append(file)\n",
    "# Upload these files to S3\n",
    "for file in pdf_files:\n",
    "    s3_client.upload_file(f'{folder_path}/{file}', basic_configurations.BucketName, f'{file}')\n",
    "    print(f'Uploaded {file} to {basic_configurations.BucketName}')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will now use textract to convert documents\n",
    "To do this, we will create a simple function that can perform OCR on these PDF files using the textract API via the boto3 package. Before building an actual pipeline for the same, we can try and see how to interpret the output of the text recognition process. \n",
    "\n",
    "We start with a simple page: Page number 45 of 96 in BV12- British Rule in south India. This should be an easy task. We will use `FeatureTypes = ['TABLES']` for the time being. Note that we are first analyzing the document here.\n",
    "\n",
    "The code below shows how we can analyze the text fully in a document and then use the API responses to get the information we need about different elements in the text. This information is then used to annotate the page with bounding boxes as necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: IN_PROGRESS. Waiting...\n",
      "Job status: IN_PROGRESS. Waiting...\n",
      "Job status: IN_PROGRESS. Waiting...\n",
      "Job status: IN_PROGRESS. Waiting...\n",
      "Job status: IN_PROGRESS. Waiting...\n",
      "Job status: IN_PROGRESS. Waiting...\n",
      "Job status: IN_PROGRESS. Waiting...\n"
     ]
    }
   ],
   "source": [
    "document_name =  'CPM-03-Reports-of-Agitation-in-Bihar-1893.pdf'\n",
    "page_number = '45'\n",
    "response = textract.start_document_analysis(\n",
    "    DocumentLocation={\n",
    "        'S3Object': {\n",
    "            'Bucket': basic_configurations.BucketName,\n",
    "            'Name': document_name\n",
    "        }\n",
    "    },\n",
    "    FeatureTypes=['TABLES']\n",
    ")\n",
    "# Print the job ID\n",
    "job_id = response['JobId']\n",
    "# Polling the job status\n",
    "while True:\n",
    "    job_status = textract.get_document_analysis(JobId=job_id)\n",
    "    status = job_status['JobStatus']\n",
    "    if status in ['SUCCEEDED', 'FAILED']:\n",
    "        break\n",
    "    print(f\"Job status: {status}. Waiting...\")\n",
    "    time.sleep(5)  # Wait for 5 seconds before polling again\n",
    "\n",
    "# Initialize variables\n",
    "next_token = None\n",
    "blocks = []\n",
    "while True:\n",
    "    if next_token:\n",
    "        response = textract.get_document_analysis(JobId=job_id, NextToken=next_token)\n",
    "    else:\n",
    "        response = textract.get_document_analysis(JobId=job_id)\n",
    "    blocks.extend(response['Blocks'])\n",
    "    if 'NextToken' in response:\n",
    "        next_token = response['NextToken']\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved to output_artifacts folder\n"
     ]
    }
   ],
   "source": [
    " # Now that we have the full document analysis, we can just get the information for page 45\n",
    "page_blocks = [block for block in blocks if block['Page'] == int(1)]\n",
    "artefact_path = 'output_artifacts'\n",
    "# We can now begin the process of annotating the image\n",
    "images = convert_from_path(f'{folder_path}/{document_name}', \n",
    "                           first_page=int(1), \n",
    "                           last_page=int(1))\n",
    "page_image = images[0]\n",
    "page_image.save(f'{artefact_path}/cpm03-page1.jpg')\n",
    "# Draw bounding boxes on the image\n",
    "draw = ImageDraw.Draw(page_image)\n",
    "for block in page_blocks:\n",
    "    if block['BlockType'] == 'LINE':\n",
    "        # Draw the bounding box\n",
    "        box = block['Geometry']['BoundingBox']\n",
    "        width, height = page_image.size\n",
    "        polygon_coords = [\n",
    "            (point['X']*width, point['Y']*height)\n",
    "            for point in block['Geometry']['Polygon']\n",
    "        ]\n",
    "        draw.polygon(polygon_coords, outline='red', width=3)\n",
    "page_image.save(f'{artefact_path}/cpm03-page1-annotated.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an OCR pipeline.\n",
    "\n",
    "We can now write a simple function to take in a pdf file from the archives, perform an OCR and then collect all the text after removing some watermarks and other information into a raw text file. We will also simultaneoulsy load the output from the textract API into a json object in S3 so that they can be referenced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file(file_name: str, configurations: BasicConfigurations, output_key_prefix: str):\n",
    "        \"\"\"\n",
    "        Calls the textract API and stores outpout in S3\n",
    "        \"\"\"\n",
    "        # Create clients\n",
    "        s3_client = boto3.client('s3')\n",
    "        textract = boto3.client('textract', region_name='ap-south-1')\n",
    "        # Call the API\n",
    "        response = textract.start_document_analysis(\n",
    "                DocumentLocation={\n",
    "                        'S3Object': {\n",
    "                        'Bucket': configurations.BucketName,\n",
    "                        'Name': file_name\n",
    "                        }\n",
    "                },\n",
    "                FeatureTypes=['TABLES']\n",
    "        )\n",
    "        # Poll for the response\n",
    "        # Print the job ID\n",
    "        job_id = response['JobId']\n",
    "        # Polling the job status\n",
    "        while True:\n",
    "                job_status = textract.get_document_analysis(JobId=job_id)\n",
    "                status = job_status['JobStatus']\n",
    "                if status in ['SUCCEEDED', 'FAILED']:\n",
    "                        break\n",
    "                print(f\"Job status: {status}. Waiting...\")\n",
    "                time.sleep(5)  # Wait for 5 seconds before polling again       \n",
    "        # Initialize variables\n",
    "        next_token = None\n",
    "        blocks = []\n",
    "        while True:\n",
    "                if next_token:\n",
    "                        response = textract.get_document_analysis(JobId=job_id, NextToken=next_token)\n",
    "                else:\n",
    "                        response = textract.get_document_analysis(JobId=job_id)\n",
    "                blocks.extend(response['Blocks'])\n",
    "                if 'NextToken' in response:\n",
    "                        next_token = response['NextToken']\n",
    "                else:\n",
    "                        break\n",
    "        # Write all the blocks to S3 in a specific location\n",
    "        output_key = f'extraction_detal/{output_key_prefix}/apiResponse.json'\n",
    "        # Write the blocks to S3 as a json file (in a byte format)\n",
    "        s3_client.put_object(\n",
    "                Bucket=configurations.BucketName,\n",
    "                Key=output_key,\n",
    "                Body=str(blocks).encode('utf-8')\n",
    "        )\n",
    "        # Now loop through the blocks get the 'Text' attribute from the block and keep appending with a space to a raw_text string\n",
    "        raw_text = ''\n",
    "        for block in blocks:\n",
    "                if block['BlockType'] == 'LINE':\n",
    "                        text = block['Text']\n",
    "                        if 'cpsindia' in text.lower() or 'centre for policy' in text.lower() or 'cps-' in text.lower():\n",
    "                                continue\n",
    "                        raw_text += block['Text'] + ' '\n",
    "        # Write the raw text to S3\n",
    "        output_key = f'extraction_detal/{output_key_prefix}/rawText.txt'\n",
    "        s3_client.put_object(\n",
    "                Bucket=configurations.BucketName,\n",
    "                Key=output_key,\n",
    "                Body=raw_text.encode('utf-8')\n",
    "        )\n",
    "        print(f'Finished processing {file_name} and wrote the output to S3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "convert_file('BV-12-British-Rule-in-South-India.pdf', basic_configurations, 'bv12')\n",
    "end = time.time()\n",
    "print(f'Time Taken: {end-start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization\n",
    "We can now perform the actual task of text summarization. We will use the openAI API and send in the entire text as a chunk of information and then get the output response. This is a risky approach, but worth a try.\n",
    "We will be writing a function to take in the text from an OCR output and then directly insert it into a prompt which will be fed to the open AI completions API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_without_chunking(text_key: str, configurations: BasicConfigurations, temperature: float = 0.1):\n",
    "    \"\"\"\n",
    "    Summarizes the text from the S3 object\n",
    "    \"\"\"\n",
    "    # Create an s3 client \n",
    "    s3_client = boto3.client('s3')\n",
    "    # Create a secrets manager client in ap-south-1 using boto3\n",
    "    secrets_manager = boto3.client('secretsmanager', region_name='ap-south-1')\n",
    "    # Get the OpenAI API key from the secrets manager\n",
    "    secret = secrets_manager.get_secret_value(SecretId='openai/key')\n",
    "    # Extract the api_key from the secret\n",
    "    api_key = secret['SecretString']\n",
    "    # Convert the api_key to a dictionary and get the api_key from it\n",
    "    api_key = eval(api_key)['api_key']\n",
    "    client = OpenAI(\n",
    "        api_key=api_key,  # this is also the default, it can be omitted\n",
    "    )\n",
    "    # download the file rawText.txt from the S3 bucket and store the text in the file in a variable raw_text\n",
    "    response = s3_client.get_object(Bucket=configurations.BucketName, Key=f'extraction_detal/{text_key}/rawText.txt')\n",
    "    raw_text = response['Body'].read().decode('utf-8')\n",
    "    # Now call the completions API\n",
    "    \n",
    "    try:\n",
    "        print(\"Sending request to GPT-4...\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"\"\"You are a helpful assistant that summarizes text. The text is produced by a OCR system on old documents. \n",
    "                 There will be some errors and the text may not be perfect. Take that into account when summarizing the text. Use ONLY the text provided and donot add context from outside. Make sure that the summary is atmost 400 words long and atleast 300 words long. \n",
    "                 I donot want to exceed these limita. Touch upon all the important points in the text.\n",
    "                 In your response provide the output as a JSON object with the key 'summary' and the value as the summarized text. Use the key 'locations' to provide a list of locations referenced in the text.\n",
    "                 Use the key 'people' to provide a list of people referenced in the text, I mean people with actual names like John Jopkins, Shivaji. Use the key 'organizations' to provide a list of organizations referenced in the text.\n",
    "                 Use the key 'groups' to provide a list of caste names referenced in the text such as Brahmins, Paraiyar (try to get a minimum of 5). In enlisting be as expansive as you can. I should be able to convert this to a python dictionary.\n",
    "                 \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Summarize the following text: {raw_text}\"}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        summary = response.choices[0].message.content\n",
    "        output_key = f'extraction_detal/{text_key}/summaries.json'\n",
    "        s3_client.put_object(\n",
    "                Bucket=configurations.BucketName,\n",
    "                Key=output_key,\n",
    "                Body=str(summary).encode('utf-8')\n",
    "        )\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to GPT-4...\n"
     ]
    }
   ],
   "source": [
    "# Call the API\n",
    "x = summarize_text_without_chunking('bv12', basic_configurations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with documents\n",
    "Here, we design a simple system to chunk the raw text, store it in a vector database and use this to perform Retrieval Augmented Generation for answering questions about the document itself.\n",
    "1. `chunk_text` - chunks the text which is the raw text of the document and it has some overlap defined which means that two adjacent chunks of text will have some amout of overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=500, overlap=100):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - overlap  # Overlap for continuity\n",
    "    return chunks\n",
    "\n",
    "def create_and_populate_vector_data_base(doc_key:str, configurations: BasicConfigurations):\n",
    "    \"\"\"\n",
    "    Creates and populates a vector database while using the OpenAI embedings API.\n",
    "    We just specify the document key and the function will take care of the rest.\n",
    "    \"\"\"\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "    # Download rawText from S3\n",
    "    response = s3_client.get_object(Bucket=configurations.BucketName, Key=f'extraction_detal/{doc_key}/rawText.txt')\n",
    "    raw_text = response['Body'].read().decode('utf-8')\n",
    "    # chunk the text\n",
    "    chunks = chunk_text(raw_text)\n",
    "    # Create an OpenAI client\n",
    "    secrets_manager = boto3.client('secretsmanager', region_name='ap-south-1')\n",
    "    # Get the OpenAI API key from the secrets manager\n",
    "    secret = secrets_manager.get_secret_value(SecretId='openai/key')\n",
    "    # Extract the api_key from the secret\n",
    "    api_key = secret['SecretString']\n",
    "    # Convert the api_key to a dictionary and get the api_key from it\n",
    "    api_key = eval(api_key)['api_key']\n",
    "    client = OpenAI(\n",
    "        api_key=api_key,  # this is also the default, it can be omitted\n",
    "    )\n",
    "    # Create a vector database\n",
    "    dimension = 1536\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    # Populate the vector database\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i % 10 == 0:\n",
    "            print(f'Processing chunk {i} of {len(chunks)}')\n",
    "        response = client.embeddings.create(\n",
    "            input=[chunk],\n",
    "            model=\"text-embedding-ada-002\",\n",
    "        )\n",
    "        vector = response.data[0].embedding\n",
    "        index.add(np.array([vector]).astype('float32'))\n",
    "    print(f'Finished creating and populating the vector database for {doc_key}')\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = create_and_populate_vector_data_base('cpm03', basic_configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chunk map of the raw text\n",
    "def create_chunk_map(doc_key:str, configurations: BasicConfigurations):\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "    # Download rawText from S3\n",
    "    response = s3_client.get_object(Bucket=configurations.BucketName, Key=f'extraction_detal/{doc_key}/rawText.txt')\n",
    "    raw_text = response['Body'].read().decode('utf-8')\n",
    "    # chunk the text\n",
    "    chunks = chunk_text(raw_text)\n",
    "    chunk_map = {i: chunk for i, chunk in enumerate(chunks)}\n",
    "    return chunk_map\n",
    "\n",
    "def search_vector_database(query:str, db, chunk_map, k=20):\n",
    "    \"\"\"\n",
    "    Searches the vector database for the most similar vectors to the query\n",
    "    \"\"\"\n",
    "    # Create an OpenAI client\n",
    "    secrets_manager = boto3.client('secretsmanager', region_name='ap-south-1')\n",
    "    # Get the OpenAI API key from the secrets manager\n",
    "    secret = secrets_manager.get_secret_value(SecretId='openai/key')\n",
    "    # Extract the api_key from the secret\n",
    "    api_key = secret['SecretString']\n",
    "    # Convert the api_key to a dictionary and get the api_key from it\n",
    "    api_key = eval(api_key)['api_key']\n",
    "    client = OpenAI(\n",
    "        api_key=api_key,  # this is also the default, it can be omitted\n",
    "    )\n",
    "    dimension = 1536\n",
    "    # Embed the query\n",
    "    response = client.embeddings.create(\n",
    "        input=[query],\n",
    "        model=\"text-embedding-ada-002\",\n",
    "    )\n",
    "    vector = response.data[0].embedding\n",
    "    query_embedding = np.array([vector]).astype('float32')\n",
    "    # Search the index\n",
    "    D, I = db.search(query_embedding, k)\n",
    "    # Return the chunks\n",
    "    return [chunk_map[idx] for idx in I[0]]\n",
    "\n",
    "def answer_document_question(doc_key: str,\n",
    "                             question: str,\n",
    "                             configurations: BasicConfigurations, \n",
    "                             db):\n",
    "    \"\"\"\n",
    "    Answers a question from the document\n",
    "    \"\"\"\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "    # Read in the Raw Summary from the document\n",
    "    response = s3_client.get_object(Bucket=configurations.BucketName, Key=f'extraction_detal/{doc_key}/summaries.json')\n",
    "    # Store the response as a string\n",
    "    broad_context = response['Body'].read().decode('utf-8')\n",
    "    # Create a vector database\n",
    "    chunk_map = create_chunk_map(doc_key, configurations)\n",
    "    # Search the vector database\n",
    "    relevant_chunks = search_vector_database(question, db, chunk_map)\n",
    "    # Concatenate the chunks\n",
    "    specific_context = ' '.join(relevant_chunks)\n",
    "    # Master Content\n",
    "    master_content = f\"\"\"\n",
    "    You are a helpful assistant that will answer some questions given a \n",
    "    broad context and a specific context. The broad context given as <<BROAD CONTEXT>>\n",
    "    is a summary of the document from which you are answering questions. The specific context \n",
    "    given as <<SPECIFIC CONTEXT>> are specific chunks of text related to the question\n",
    "    from the document. The question is specified as <<QUESTION>>. You should answer the \n",
    "    question using information only from the broad and specific context. You should not\n",
    "    provide information from outside the context. You should provide the answer as <<ANSWER>> followed\n",
    "    by the actual answer and your level of confidence as <<CONFIDENCE>> which can be HIGH, MEDIUM or LOW.set_matplotlib_close\n",
    "    \"\"\"\n",
    "    question_prompt = f\"\"\"\n",
    "    <<QUESTION>>: {question}\n",
    "    <<BROAD CONTEXT>>: {broad_context}\n",
    "    <<SPECIFIC CONTEXT>>: {specific_context}\n",
    "    \"\"\"\n",
    "    # Get the OpenAI API key from the secrets manager\n",
    "    secrets_manager = boto3.client('secretsmanager', region_name='ap-south-1')\n",
    "    secret = secrets_manager.get_secret_value(SecretId='openai/key')\n",
    "    # Extract the api_key from the secret\n",
    "    api_key = secret['SecretString']\n",
    "    # Convert the api_key to a dictionary and get the api_key from it\n",
    "    api_key = eval(api_key)['api_key']\n",
    "    client = OpenAI(\n",
    "        api_key=api_key,  # this is also the default, it can be omitted\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": master_content},\n",
    "                {\"role\": \"user\", \"content\": question_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "        )\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: The agitations discussed are about the anti-kine-killing movement, which initially started as a religious and peaceful advocacy for the protection of cows but later escalated into significant civil unrest. This unrest involved coercion and violence, particularly from itinerant propagandists from outside the province. The agitation led to tensions between different community groups, prompting the need for stringent administrative actions to manage and prevent further escalation of communal unrest.\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'What are these agitations about?', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: Gopalanand Swami\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'Name a prominent person who participated in these agitations. Just one is enough', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: Gopalanand Swami played a significant role as an organizer of Sabhas and a preacher of their doctrines. He was involved in the anti-kine-killing agitation, where his preaching led to significant unrest and eventually to his arrest and imprisonment for two years. He was known for his ability to organize and promote the doctrines of the Sabhas, which contributed to the spread of the movement and the associated disturbances.\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'What role did Gopalanad Swami Play?', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: The approximate time frame of the agitations is primarily around the late 19th century, specifically highlighted around the years 1891, 1892, and 1893. The locations of these agitations include various districts and towns across Bengal and the surrounding areas, such as Gaya, Patna, Darbhanga, Madhubani, Shahabad, Muzaffarpur, and others mentioned in the broad context.\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'What is the approximate time frame and locations of these agitations?', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: Yes, some Muslims did participate in the agitations.\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'Did any muslims participate in these agitations?', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<<ANSWER>>: The Muslims who participated in the agitations include Moulvi Maniralam, who was described as a rabid anti-Englishman and joined the Hindus in other agitations. Another participant was a Maulvi from the district of Azamgarh, who was involved in a discussion at a fair and was confounded by Pandit Jagat Narain's responses. Additionally, four Muslims named Mohammed Ali, Race, Tiktiq Ali Bakhah of Dumraon, Ali Mohammad of Buzar, and Khuda Bakbah of Balia renounced the use of flesh following the discomfiture of the Maulvi from Azamgarh.\\n\\n<<CONFIDENCE>>: HIGH\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'Name a few muslims who participated in these agitations and their role?', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: The role of Muslims in the agitation was primarily characterized by their involvement in counter-agitations and forming vigilance committees to stay informed and possibly coordinate with Europeans. They were also subjects of rumors and misinformation, which alarmed them and potentially incited further unrest. There were instances where Muslims were reported to be forming groups to enforce their interests, particularly in response to the Hindu-led anti-kine-killing agitation. Additionally, there were mentions of Muslims being encouraged to contribute to the support of additional police due to local tensions, and there were fears among them that the government might not be able to protect them adequately.\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'What was the role of Muslims in this agitation?', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: Yes, some Muslims did support the Hindus in their agitations. The specific context mentions Moulvi Maniralam, a Muhammadan who is described as a rabid anti-Englishman, joining the Hindus in other agitations.\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'Did any Muslims support the Hindus at all?', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: The castes among Hindus that were most active in these agitations were the Bunniahs and Kshatriyas (Kniths).\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'What castes among Hindus were most active in these agitations?', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: Yes, Brahmins were active as Banias and Kshatriyas. The specific context mentions various activities and roles taken by Brahmins, such as being appointed as accountants and curators of Gaushalas, participating in agitations, and preaching against kine-killing. This indicates their involvement in activities typically associated with the Bania (trader) and Kshatriya (warrior) roles, such as managing funds and leading social movements.\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'Were Brahmins not active as Banias and Kshatriyas?', \n",
    "                         basic_configurations, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<ANSWER>>: At the Brahmapur Fair held on 25th April 1839, a group of preachers set up their tent and began preaching. Notable attendees included Pandit Jagat Narain, Pandit Kishori Lal, Pandit Har Narain, Pandit Mahabir Pershad, and others from various locations such as Benares and Arrah. The fair was significant for the anti-kine-killing movement, as the lives of several cows and bullocks were saved from being sold to butchers. Donations were collected to support the cause, and the event proceeded peacefully under the supervision of a Joint-Magistrate. However, a previous fair in April 1891 at Berhampore saw a violent incident where a large mob of armed Hindus attacked butchers, leading to police intervention and the arrest of a key agitator, Gopalanand Swami.\\n\\n<<CONFIDENCE>>: HIGH'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_document_question('cpm03', 'What happened in the Brahmapur Fair?', \n",
    "                         basic_configurations, m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
